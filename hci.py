# -*- coding: utf-8 -*-
"""Welcome to Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

# Install necessary libraries
!pip install transformers
!pip install torch

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load a pre-trained GPT-2 model
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

# Define a function to interact with the chatbot
def generate_response(user_input, chat_history=[], max_history_turns=5):
    # Add the user input to the chat history
    chat_history.append(user_input)

    # Keep only the last few turns of the conversation in history
    if len(chat_history) > max_history_turns * 2: # *2 because each turn has user input and AI response
        chat_history = chat_history[-(max_history_turns * 2):]

    # Combine chat history into a single string to give the model context
    input_text = " ".join(chat_history)

    # Tokenize the input text
    input_ids = tokenizer.encode(input_text, return_tensors="pt")

    # Generate a response from the model
    with torch.no_grad():
        # Use max_new_tokens and increase max_length
        output = model.generate(input_ids, max_length=512, max_new_tokens=50, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)

    # Decode the output
    response = tokenizer.decode(output[0], skip_special_tokens=True)

    # Get the model's response (skip input part to avoid repetition)
    # Find the index where the generated response starts after the input text
    input_text_length = len(tokenizer.encode(input_text))
    response_tokens = output[0][input_text_length:]
    response = tokenizer.decode(response_tokens, skip_special_tokens=True)


    # Append the response to the chat history for next input
    chat_history.append(response.strip())

    return response.strip(), chat_history

# Simulating the chatbot conversation
def start_chat():
    print("AI Chatbot (type 'exit' to stop)")
    chat_history = []

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            print("Ending the chat session.")
            break

        response, chat_history = generate_response(user_input, chat_history)
        print("AI: ", response)

# Start the chatbot
start_chat()